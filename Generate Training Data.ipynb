{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e569d9a-7b38-4d39-9096-980e92cc34b5",
   "metadata": {},
   "source": [
    "# Simulate Ginkgo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b9027b-e5b9-4e16-8e12-125fce86ec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fccd0a9-f707-4a89-9cd0-473a337ae8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/Jet_Stream'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "017f7ca5-54d6-4888-925d-10710af98a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pickle\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "# from ginkgo import invMass_ginkgo\n",
    "# from invMass_ginkgo import *\n",
    "from invMass_ginkgo_node import *\n",
    "# from ginkgo.utils import get_logger\n",
    "\n",
    "\n",
    "# logger = get_logger(level = logging.WARNING)\n",
    "# fh = logging.FileHandler('spam.log')\n",
    "# fh.setLevel(logging.WARNING)\n",
    "# logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee94797c-c5b8-44ec-87a7-f3f5c55bc081",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ginkgo_simulator():\n",
    "    def __init__(self,\n",
    "                 rate,\n",
    "                 pt_cut,\n",
    "                 M2start,\n",
    "                 Nsamples,\n",
    "                 minLeaves,\n",
    "                 maxLeaves,\n",
    "                 maxNTry,\n",
    "                 jetType, \n",
    "                 jetP,\n",
    "                 root_rate= 1.5,\n",
    "                ):\n",
    "        \n",
    "        self.root_rate = root_rate\n",
    "        self.rate = rate\n",
    "        self.pt_cut = pt_cut\n",
    "        self.M2start = torch.tensor(M2start) # mass squared to start with\n",
    "        self.Nsamples = Nsamples\n",
    "        self.minLeaves = minLeaves\n",
    "        self.maxLeaves = maxLeaves\n",
    "        self.maxNTry = maxNTry\n",
    "        self.jetType = jetType # W or QCD \n",
    "        self.jetM = np.sqrt(M2start) # mass to start with\n",
    "        self.jetdir = np.array([1,1,1])\n",
    "        self.jetP = jetP\n",
    "        self.jetvec = self.jetP * self.jetdir / np.linalg.norm(self.jetdir)\n",
    "        self.jet4vec = np.concatenate(([np.sqrt(self.jetP ** 2 + self.jetM ** 2)], self.jetvec))\n",
    "        # logger.debug(f\"jet4vec = {self.jet4vec}\")\n",
    "        \n",
    "        if jetType == \"W\":\n",
    "            # defined in paper, W jets have a different root rate\n",
    "            self.rate=torch.tensor([self.root_rate,self.rate])\n",
    "        elif jetType == \"QCD\":\n",
    "            # QCD jets maintain the same rate throughout\n",
    "            self.rate=torch.tensor([self.rate,self.rate])\n",
    "        else:\n",
    "            raise ValueError(\"Choose a valid jet type between W or QCD\")\n",
    "\n",
    "\n",
    "\n",
    "    def simulator(self):\n",
    "\n",
    "        simulator = Simulator(jet_p = self.jet4vec,\n",
    "                                         pt_cut = float(self.pt_cut),\n",
    "                                         Delta_0 = self.M2start,\n",
    "                                         M_hard = self.jetM ,\n",
    "                                         num_samples = int(self.Nsamples),\n",
    "                                         minLeaves = int(self.minLeaves),\n",
    "                                         maxLeaves = int(self.maxLeaves),\n",
    "                                         maxNTry = int(self.maxNTry)\n",
    "                                         )\n",
    "        return simulator\n",
    "       \n",
    "    def generate(self):\n",
    "        \n",
    "        simulator = self.simulator()\n",
    "        jet_list = simulator(self.rate)\n",
    "\n",
    "        # logger.debug(f\"---\"*10)\n",
    "        # logger.debug(f\"jet_list = {jet_list}\")\n",
    "        \n",
    "        return jet_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3bc3d5-938e-45ca-b0cf-8c04497f7121",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68154703-ae39-4829-b0d4-ac27a98c3452",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate2 = torch.tensor(8.) # is this used?\n",
    "# Parameters to get ~<10 constituents to test the trellis algorithm\n",
    "pt_min = torch.tensor(4.**2)\n",
    "### Physics inspired parameters to get ~ between 20 and 50 constituents\n",
    "W_rate = 3.\n",
    "QCD_rate = 1.5\n",
    "QCD_mass = 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bb85af2-3b8e-48f6-a42d-3a78232e9275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the range of leaves that you would consider as valid generations\n",
    "minLeaves = 8 #3\n",
    "maxLeaves = 11 #100\n",
    "# number of jets you wish to generate\n",
    "Nsamples = 1\n",
    "# exponential rate parameter\n",
    "rate = 1.5\n",
    "# mass squared cut off to yield leaves\n",
    "pt_cut =  torch.tensor(1.1**2)\n",
    "# mass squared to start with\n",
    "# M2start = 80.**2\n",
    "M2start = 10.**2\n",
    "# the maximum times you are willing to try to get Nsamples\n",
    "maxNTry = 1\n",
    "# jetP=400.\n",
    "jetP=4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "041cad5e-23b7-4cfb-ada9-758837a74c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0\n",
      "Node 0\n",
      " Vec4: [10.77032961  2.30940108  2.30940108  2.30940108]\n",
      " Decay Rate: 1\n",
      " Mass Squared: tensor(100.)\n",
      " Log Likelihood: -8.343492298879692\n",
      " DIJ List: -8.343492298879692 0.4058080604871134 6.2180457198953585 2.6976042179282573\n",
      "\n",
      "Node 1\n",
      " Vec4: [ 0.76938436 -0.54658424 -0.36753286  0.07284879]\n",
      " Decay Rate: tensor(0.1328)\n",
      " Mass Squared: tensor(0.1528)\n",
      " Log Likelihood: 0\n",
      " DIJ List:\n",
      "\n",
      "Node 2\n",
      " Vec4: [10.00094525  2.85598532  2.67693394  2.23655228]\n",
      " Decay Rate: tensor(0.7969)\n",
      " Mass Squared: tensor(79.6941)\n",
      " Log Likelihood: -8.145483284750053\n",
      " DIJ List: -8.145483284750053 0.21895900973474589 2.573883307201682 1.6829860779701085\n",
      "\n",
      "Node 3\n",
      " Vec4: [8.86249938 2.87466492 1.86852712 2.80779836]\n",
      " Decay Rate: tensor(0.7391)\n",
      " Mass Squared: tensor(58.9051)\n",
      " Log Likelihood: -7.991703301229545\n",
      " DIJ List: -7.991703301229545 0.08575627687418498 1.0156853948042104 0.00016964675240789778\n",
      "\n",
      "Node 4\n",
      " Vec4: [ 1.1384456  -0.01867968  0.80840674 -0.57124614]\n",
      " Decay Rate: tensor(0.2014)\n",
      " Mass Squared: tensor(0.3159)\n",
      " Log Likelihood: 0\n",
      " DIJ List:\n",
      "\n",
      "Node 5\n",
      " Vec4: [ 0.28934727 -0.01068778 -0.00726624  0.13143374]\n",
      " Decay Rate: tensor(0.7716)\n",
      " Mass Squared: tensor(0.0663)\n",
      " Log Likelihood: 0\n",
      " DIJ List:\n",
      "\n",
      "Node 6\n",
      " Vec4: [8.57315201 2.88535266 1.87579334 2.67636459]\n",
      " Decay Rate: tensor(0.9251)\n",
      " Mass Squared: tensor(54.4921)\n",
      " Log Likelihood: -8.74057939604766\n",
      " DIJ List: -8.74057939604766 0.18503163127305342 4.354358501066041 30.256063940084562\n",
      "\n",
      "Node 7\n",
      " Vec4: [5.41949745 2.07597036 4.38444938 0.96970397]\n",
      " Decay Rate: tensor(0.0899)\n",
      " Mass Squared: tensor(4.8976)\n",
      " Log Likelihood: -4.515813260831901\n",
      " DIJ List: -4.515813260831901 0.011795922224982656 0.1117053220903759 0.3783603848391846\n",
      "\n",
      "Node 8\n",
      " Vec4: [ 3.15365428  0.80938221 -2.5086561   1.70666053]\n",
      " Decay Rate: tensor(0.0032)\n",
      " Mass Squared: tensor(0.0844)\n",
      " Log Likelihood: 0\n",
      " DIJ List:\n",
      "\n",
      "Node 9\n",
      " Vec4: [3.48459637 1.65883177 2.59193025 0.59569903]\n",
      " Decay Rate: tensor(0.4732)\n",
      " Mass Squared: tensor(2.3177)\n",
      " Log Likelihood: -3.665330677785941\n",
      " DIJ List: -3.665330677785941 0.015694924978483932 0.05141404898989587 0.08260961828374044\n",
      "\n",
      "Node 10\n",
      " Vec4: [1.93490108 0.4171386  1.79251913 0.37400493]\n",
      " Decay Rate: tensor(0.4546)\n",
      " Mass Squared: tensor(0.2168)\n",
      " Log Likelihood: 0\n",
      " DIJ List:\n",
      "\n",
      "Node 11\n",
      " Vec4: [2.13034658 0.96117391 1.53361789 0.17375109]\n",
      " Decay Rate: tensor(0.5317)\n",
      " Mass Squared: tensor(1.2323)\n",
      " Log Likelihood: -2.538113325395652\n",
      " DIJ List: -2.538113325395652 0.6212187971476771 1.6051696665098067 0.3453254731510159\n",
      "\n",
      "Node 12\n",
      " Vec4: [1.35424993 0.69765792 1.05831246 0.42194797]\n",
      " Decay Rate: tensor(0.2894)\n",
      " Mass Squared: tensor(0.0492)\n",
      " Log Likelihood: 0\n",
      " DIJ List:\n",
      "\n",
      "Node 13\n",
      " Vec4: [0.5055145  0.46379717 0.00504984 0.17431713]\n",
      " Decay Rate: tensor(0.0132)\n",
      " Mass Squared: tensor(0.0100)\n",
      " Log Likelihood: 0\n",
      " DIJ List:\n",
      "\n",
      "Node 14\n",
      " Vec4: [ 1.62483208e+00  4.97376736e-01  1.52856805e+00 -5.66043828e-04]\n",
      " Decay Rate: tensor(0.0456)\n",
      " Mass Squared: tensor(0.0562)\n",
      " Log Likelihood: 0\n",
      " DIJ List:\n",
      "\n",
      "  ┌1\n",
      " 0┤\n",
      "  │ ┌4\n",
      "  └2┤\n",
      "    │ ┌5\n",
      "    └3┤\n",
      "      │ ┌8\n",
      "      └6┤\n",
      "        │ ┌10\n",
      "        └7┤\n",
      "          │ ┌12\n",
      "          └9┤\n",
      "            │  ┌13\n",
      "            └11┤\n",
      "               └14\n",
      "Number of nodes:  15\n",
      "-43.940515544920444\n",
      "Sample 1\n",
      "Node 0\n",
      " Vec4: [10.77032961  2.30940108  2.30940108  2.30940108]\n",
      " Decay Rate: 1\n",
      " Mass Squared: tensor(100.)\n",
      " Log Likelihood: -10.110156327047417\n",
      " DIJ List: -10.110156327047417 0.9581864212841562 5.271858497231515 5.306103533953655\n",
      "\n",
      "Node 1\n",
      " Vec4: [ 3.54285438  0.90669368  0.42942098 -2.33749978]\n",
      " Decay Rate: tensor(0.2446)\n",
      " Mass Squared: tensor(6.0814)\n",
      " Log Likelihood: -4.840723543920585\n",
      " DIJ List: -4.840723543920585 1.0320687348128907 0.44322205523098085 0.1163029120819929\n",
      "\n",
      "Node 2\n",
      " Vec4: [7.22747524 1.40270739 1.87998009 4.64690086]\n",
      " Decay Rate: tensor(0.2514)\n",
      " Mass Squared: tensor(25.1408)\n",
      " Log Likelihood: -7.606458931722709\n",
      " DIJ List: -7.606458931722709 0.11134851847217081 0.2598922211192118 0.25681360250045293\n",
      "\n",
      "Node 3\n",
      " Vec4: [ 2.46453238  0.25158448  0.44621576 -1.65168359]\n",
      " Decay Rate: tensor(0.5070)\n",
      " Mass Squared: tensor(3.0835)\n",
      " Log Likelihood: -4.065340905942985\n",
      " DIJ List: -4.065340905942985 1.737359856450426 0.22742871703754694 0.01793670929594752\n",
      "\n",
      "Node 4\n",
      " Vec4: [ 1.078322    0.6551092  -0.01679478 -0.68581619]\n",
      " Decay Rate: tensor(0.5216)\n",
      " Mass Squared: tensor(0.2630)\n",
      " Log Likelihood: 0\n",
      " DIJ List:\n",
      "\n",
      "Node 5\n",
      " Vec4: [3.37271104 0.16839589 0.97969233 2.84712521]\n",
      " Decay Rate: tensor(0.0907)\n",
      " Mass Squared: tensor(2.2809)\n",
      " Log Likelihood: -2.9135411675358496\n",
      " DIJ List: -2.9135411675358496 0.6909931973337381 0.6316920714065034 0.24151348160784022\n",
      "\n",
      "Node 6\n",
      " Vec4: [3.8547642  1.2343115  0.90028776 1.79977565]\n",
      " Decay Rate: tensor(0.7564)\n",
      " Mass Squared: tensor(9.2860)\n",
      " Log Likelihood: -5.147630244054862\n",
      " DIJ List: -5.147630244054862 0.8964838696178472 2.1078223689680473 0.9781341745085317\n",
      "\n",
      "Node 7\n",
      " Vec4: [ 0.83266495 -0.01614981  0.36144705 -0.7159927 ]\n",
      " Decay Rate: tensor(0.0161)\n",
      " Mass Squared: tensor(0.0498)\n",
      " Log Likelihood: 0\n",
      " DIJ List:\n",
      "\n",
      "Node 8\n",
      " Vec4: [ 1.63186746  0.2677343   0.08476873 -0.93569091]\n",
      " Decay Rate: tensor(0.7272)\n",
      " Mass Squared: tensor(1.7086)\n",
      " Log Likelihood: -2.7018235619450293\n",
      " DIJ List: -2.7018235619450293 25.955724887994894 2.3867177254178333 0.1334416785164047\n",
      "\n",
      "Node 9\n",
      " Vec4: [ 1.32753913 -0.52697386  0.32346008  1.06776636]\n",
      " Decay Rate: tensor(0.1052)\n",
      " Mass Squared: tensor(0.2399)\n",
      " Log Likelihood: 0\n",
      " DIJ List:\n",
      "\n",
      "Node 10\n",
      " Vec4: [2.04517191 0.69536975 0.65623226 1.77935885]\n",
      " Decay Rate: tensor(0.0984)\n",
      " Mass Squared: tensor(0.1024)\n",
      " Log Likelihood: 0\n",
      " DIJ List:\n",
      "\n",
      "Node 11\n",
      " Vec4: [2.62131662 1.50821755 0.27656899 1.51662348]\n",
      " Decay Rate: tensor(0.2391)\n",
      " Mass Squared: tensor(2.2199)\n",
      " Log Likelihood: -2.9036705787564\n",
      " DIJ List: -2.9036705787564 0.3606147238737596 0.6933045186183985 0.015128989931280593\n",
      "\n",
      "Node 12\n",
      " Vec4: [ 1.23344758 -0.27390605  0.62371876  0.28315216]\n",
      " Decay Rate: tensor(0.4029)\n",
      " Mass Squared: tensor(0.9772)\n",
      " Log Likelihood: 0\n",
      " DIJ List:\n",
      "\n",
      "Node 13\n",
      " Vec4: [ 1.127952    0.14024873 -0.19036915 -0.88864796]\n",
      " Decay Rate: tensor(0.2497)\n",
      " Mass Squared: tensor(0.4267)\n",
      " Log Likelihood: 0\n",
      " DIJ List:\n",
      "\n",
      "Node 14\n",
      " Vec4: [ 0.50391546  0.12748556  0.27513788 -0.04704295]\n",
      " Decay Rate: tensor(0.3736)\n",
      " Mass Squared: tensor(0.1598)\n",
      " Log Likelihood: 0\n",
      " DIJ List:\n",
      "\n",
      "Node 15\n",
      " Vec4: [1.63314218 1.36091347 0.26547602 0.81610019]\n",
      " Decay Rate: tensor(0.1201)\n",
      " Mass Squared: tensor(0.0786)\n",
      " Log Likelihood: 0\n",
      " DIJ List:\n",
      "\n",
      "Node 16\n",
      " Vec4: [0.98817455 0.14730414 0.01109299 0.70052335]\n",
      " Decay Rate: tensor(0.2090)\n",
      " Mass Squared: tensor(0.4639)\n",
      " Log Likelihood: 0\n",
      " DIJ List:\n",
      "\n",
      "    ┌4\n",
      "  ┌1┤\n",
      "  │ │ ┌7\n",
      "  │ └3┤\n",
      "  │   │ ┌13\n",
      "  │   └8┤\n",
      "  │     └14\n",
      " 0┤\n",
      "  │   ┌9\n",
      "  │ ┌5┤\n",
      "  │ │ └10\n",
      "  └2┤\n",
      "    │ ┌12\n",
      "    └6┤\n",
      "      │  ┌15\n",
      "      └11┤\n",
      "         └16\n",
      "Number of nodes:  17\n",
      "-40.289345260925835\n"
     ]
    }
   ],
   "source": [
    "jetType =\"QCD\"\n",
    "\n",
    "def nodeSum(node):\n",
    "    if not node:\n",
    "        return 0\n",
    "    return node.logLH + nodeSum(node.left) + nodeSum(node.right)\n",
    "\n",
    "ginkgo = ginkgo_simulator(\n",
    "                 rate,\n",
    "                 pt_cut ,\n",
    "                 M2start,\n",
    "                 Nsamples,\n",
    "                 minLeaves,\n",
    "                 maxLeaves,\n",
    "                 maxNTry,\n",
    "                 jetType, \n",
    "                 jetP)\n",
    "\n",
    "jet_list = []\n",
    "for i in range(2):\n",
    "    print(f\"Sample {i}\")\n",
    "    QCD_jets = ginkgo.generate()\n",
    "    print(\"Number of nodes: \" , len(QCD_jets))\n",
    "    QCD_jets[0].llhSum = nodeSum(QCD_jets[0])\n",
    "    print(QCD_jets[0].llhSum)\n",
    "    #if len(QCD_jets) == 21:\n",
    "    jet_list.append(QCD_jets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3549ff5f-ba90-450d-a8d3-b1e1dcbdecce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a99569c5-8be3-4b1b-a368-f517ffc5b77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705ea96e-c805-4976-9106-53e772da2a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd80bf1a-6bcf-4d72-a091-0ba874210b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datadict(jet):\n",
    "    min_log_lik = 0\n",
    "    n = len(jet)//2 + 1\n",
    "    vec4s = np.zeros([n,4])\n",
    "    leaves = []\n",
    "    \n",
    "    \n",
    "    i = 0\n",
    "    for node in jet:\n",
    "        if node.logLH < min_log_lik:\n",
    "            min_log_lik = node.logLH\n",
    "        if node.left is None and node.right is None:\n",
    "            vec4s[i] = node.vec4\n",
    "            i += 1\n",
    "            leaves.append(node)\n",
    "    ddict = {\n",
    "        'data' : vec4s,\n",
    "        'llh': jet[0].llhSum,\n",
    "        }\n",
    "    print(\"total nodes: \", len(jet), \"leaf nodes: \" , i, \"ground truth likelihood: \" , min_log_lik)\n",
    "    return ddict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f4d9701-32d2-4ca1-8f7d-ac3e8617160b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total nodes:  15 leaf nodes:  8 ground truth likelihood:  -8.74057939604766\n",
      "-43.940515544920444\n",
      "total nodes:  17 leaf nodes:  9 ground truth likelihood:  -10.110156327047417\n",
      "-40.289345260925835\n",
      "-42.114930402923136\n"
     ]
    }
   ],
   "source": [
    "#jet = jet_list[2]\n",
    "#print(len(jet))\n",
    "\n",
    "ddict = {}\n",
    "\n",
    "sum = 0 \n",
    "for i,jet in enumerate(jet_list):\n",
    "    ddict[i] = make_datadict(jet)\n",
    "    sum += ddict[i]['llh']\n",
    "    print(ddict[i]['llh'])\n",
    "    #print(ddict[i]['ground_truth_likelihood'])\n",
    "print(sum/len(jet_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2024f767-e1c3-4ecd-a78c-b1ee0ee45c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6691c211-ea14-4417-8136-d31ae79af1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('withSum_2jets.p', 'wb') as handle:\n",
    "    pickle.dump(ddict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae26dd0b-101a-4559-8bc5-4294f5204431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<node.jetNode at 0x7f1986d5b2d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jet_list[0][0].left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fd0c45cf-400a-435b-8b68-61f2f52dbc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jet_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f0834c3-723f-4e8e-bfa2-f979f162bb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-43.940515544920444"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jet_list[0][0].llhSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31e683fd-1d9e-4e3a-abfc-a66d802ae775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.77032961,  2.30940108,  2.30940108,  2.30940108])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jet_list[0][0].vec4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "46883f3b-2e95-45f8-832f-439db2da31de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 5]\n",
      "[13, 4]\n",
      "[4, 1]\n",
      "[1.35424993 0.69765792 1.05831246 0.42194797]\n",
      "[ 0.28934727 -0.01068778 -0.00726624  0.13143374]\n",
      "\n",
      "[0.5055145  0.46379717 0.00504984 0.17431713]\n",
      "[ 1.1384456  -0.01867968  0.80840674 -0.57124614]\n",
      "\n",
      "[ 1.1384456  -0.01867968  0.80840674 -0.57124614]\n",
      "[ 0.76938436 -0.54658424 -0.36753286  0.07284879]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Inner dimensions of output shape must match inner dimensions of updates shape. Output: [2,1] updates: [0]\n\t [[node TensorScatterUpdate_166 (defined at opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'TensorScatterUpdate_166':\n  File \"opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"opt/conda/lib/python3.7/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n    app.start()\n  File \"opt/conda/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n    self.io_loop.start()\n  File \"opt/conda/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n    self.asyncio_loop.run_forever()\n  File \"opt/conda/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"opt/conda/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"opt/conda/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n    await self.process_one()\n  File \"opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n    await dispatch(*args)\n  File \"opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n    await result\n  File \"opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n    reply_content = await reply_content\n  File \"opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n    cell_id=cell_id,\n  File \"opt/conda/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n    raw_cell, store_history, silent, shell_futures, cell_id\n  File \"opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n    return runner(coro)\n  File \"opt/conda/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    coro.send(None)\n  File \"opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"var/tmp/ipykernel_3706/1324549580.py\", line 57, in <module>\n    new_mtx_KxSxA, tl, tr, tp = llh_bc(l_data_3x1x4, r_data_3x1x4, t_cut, lam)\n  File \"var/tmp/ipykernel_3706/1447384684.py\", line 105, in llh_bc\n    updates_Xx1 = valid_calc(tp_new_Xx1, tL_new_Xx1, tR_new_Xx1, decay_factor_Xx1)\n  File \"var/tmp/ipykernel_3706/1447384684.py\", line 78, in valid_calc\n    logpLR_Xx1 = tf.cast(tf.math.log(1/2), dtype = tf.float64) + get_logp(tp_Xx1, tL_Xx1, t_cut,decay_factor_Xx1) + get_logp(tpLR_Xx1, tR_Xx1, t_cut, decay_factor_Xx1)\n  File \"var/tmp/ipykernel_3706/1447384684.py\", line 64, in get_logp\n    results_Xx1 = tf.tensor_scatter_nd_update(results_Xx1, indices_Yx1, updates_Yx1)\n  File \"opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\", line 11086, in tensor_scatter_update\n    updates=updates, name=name)\n  File \"opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"opt/conda/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Inner dimensions of output shape must match inner dimensions of updates shape. Output: [2,1] updates: [0]\n\t [[{{node TensorScatterUpdate_166}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_3706/1324549580.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# b = tr_log_prob(tr, tp, tl, lam)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# c = [a,b]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;31m# print(res.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Inner dimensions of output shape must match inner dimensions of updates shape. Output: [2,1] updates: [0]\n\t [[node TensorScatterUpdate_166 (defined at opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'TensorScatterUpdate_166':\n  File \"opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"opt/conda/lib/python3.7/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n    app.start()\n  File \"opt/conda/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n    self.io_loop.start()\n  File \"opt/conda/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n    self.asyncio_loop.run_forever()\n  File \"opt/conda/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"opt/conda/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"opt/conda/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n    await self.process_one()\n  File \"opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n    await dispatch(*args)\n  File \"opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n    await result\n  File \"opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n    reply_content = await reply_content\n  File \"opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n    cell_id=cell_id,\n  File \"opt/conda/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n    raw_cell, store_history, silent, shell_futures, cell_id\n  File \"opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n    return runner(coro)\n  File \"opt/conda/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    coro.send(None)\n  File \"opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"var/tmp/ipykernel_3706/1324549580.py\", line 57, in <module>\n    new_mtx_KxSxA, tl, tr, tp = llh_bc(l_data_3x1x4, r_data_3x1x4, t_cut, lam)\n  File \"var/tmp/ipykernel_3706/1447384684.py\", line 105, in llh_bc\n    updates_Xx1 = valid_calc(tp_new_Xx1, tL_new_Xx1, tR_new_Xx1, decay_factor_Xx1)\n  File \"var/tmp/ipykernel_3706/1447384684.py\", line 78, in valid_calc\n    logpLR_Xx1 = tf.cast(tf.math.log(1/2), dtype = tf.float64) + get_logp(tp_Xx1, tL_Xx1, t_cut,decay_factor_Xx1) + get_logp(tpLR_Xx1, tR_Xx1, t_cut, decay_factor_Xx1)\n  File \"var/tmp/ipykernel_3706/1447384684.py\", line 64, in get_logp\n    results_Xx1 = tf.tensor_scatter_nd_update(results_Xx1, indices_Yx1, updates_Yx1)\n  File \"opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\", line 11086, in tensor_scatter_update\n    updates=updates, name=name)\n  File \"opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"opt/conda/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "# Example list of numbers\n",
    "numbers = [1, 4, 5, 8, 10, 12, 13, 14]\n",
    "\n",
    "\n",
    "# Sample two numbers from the list\n",
    "samp0 = random.sample(numbers, 2)\n",
    "samp1 = random.sample(numbers, 2)\n",
    "samp2 = random.sample(numbers, 2)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(samp0)\n",
    "    print(samp1)\n",
    "    print(samp2)\n",
    "    \n",
    "    print(jet_list[0][samp0[0]].vec4)\n",
    "    print(jet_list[0][samp0[1]].vec4)\n",
    "    print()\n",
    "    print(jet_list[0][samp1[0]].vec4)\n",
    "    print(jet_list[0][samp1[1]].vec4)\n",
    "    print()\n",
    "    print(jet_list[0][samp2[0]].vec4)\n",
    "    print(jet_list[0][samp2[1]].vec4)\n",
    "    \n",
    "    n_particles = 3 # K, the length of the vertical vector.\n",
    "    n_leaves = 3 # numebr of leaves\n",
    "\n",
    "    # valid pair 1\n",
    "    y = tf.constant(list(jet_list[0][samp0[0]].vec4), dtype = tf.float64)\n",
    "    z = tf.constant(list(jet_list[0][samp0[1]].vec4), dtype = tf.float64)\n",
    "\n",
    "    # valid pair 2\n",
    "    y0 = tf.constant(list(jet_list[0][samp1[0]].vec4), dtype = tf.float64)\n",
    "    z0 = tf.constant(list(jet_list[0][samp1[1]].vec4), dtype = tf.float64)\n",
    "\n",
    "    # invalid pair 1\n",
    "    y1 = tf.constant(list(jet_list[0][samp2[0]].vec4), dtype = tf.float64)\n",
    "    z1 = tf.constant(list(jet_list[0][samp2[1]].vec4), dtype = tf.float64)\n",
    "\n",
    "    l_data_3x1x4 = tf.stack([y, y0, y1], axis=0)\n",
    "    r_data_3x1x4 = tf.stack([z, z0, z1], axis=0)\n",
    "\n",
    "    l_data_3x1x4 = tf.expand_dims(l_data_3x1x4, axis = 1)\n",
    "    r_data_3x1x4 = tf.expand_dims(r_data_3x1x4, axis = 1)\n",
    "\n",
    "\n",
    "    lam = tf.constant([1.5, 1.5, 1.5], dtype = tf.float64)\n",
    "\n",
    "    lam = tf.reshape(lam, (3, 1))\n",
    "\n",
    "\n",
    "    # Assign t_cut based on max mass of leaves\n",
    "    t_cut = tf.constant(1.1**2, dtype = tf.float64)\n",
    "\n",
    "    new_mtx_KxSxA, tl, tr, tp = llh_bc(l_data_3x1x4, r_data_3x1x4, t_cut, lam)\n",
    "    a = new_mtx_KxSxA, tl, tr, tp\n",
    "    # a = tl_log_prob(tl, tp, lam)\n",
    "    # b = tr_log_prob(tr, tp, tl, lam)\n",
    "    # c = [a,b]\n",
    "    res = sess.run(a)\n",
    "    # print(res.shape)\n",
    "    print(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4205775c-81e5-4264-bfe1-8441f1c1881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llh_bc(l_data_Kx1x4, r_data_Kx1x4, t_cut, decay_factor_Kx1):\n",
    "\n",
    "            # grab left invariant mass\n",
    "            tL_Kx1 = l_data_Kx1x4[:, :,0] ** 2 - tf.norm(l_data_Kx1x4[:, :,1:], axis = -1) ** 2\n",
    "            # grab right invariant mass\n",
    "            tR_Kx1 = r_data_Kx1x4[:, :,0] ** 2 - tf.norm(r_data_Kx1x4[:, :,1:], axis = -1) ** 2\n",
    "\n",
    "            p_data_Kx1x4 = l_data_Kx1x4 + r_data_Kx1x4\n",
    "\n",
    "            tp_Kx1 = p_data_Kx1x4[:, :,0] ** 2 - tf.norm(p_data_Kx1x4[:, :,1:], axis = -1) ** 2\n",
    "\n",
    "            is_negative_Kx1 = tf.logical_or(tf.logical_or(tf.less(tL_Kx1, 0), tf.less(tR_Kx1, 0)), tf.less_equal(tp_Kx1, 0))\n",
    "\n",
    "            is_invalid_Kx1 = tf.logical_or(\n",
    "                                tf.less_equal(tp_Kx1, t_cut),\n",
    "                                tf.logical_or(\n",
    "                                   tf.logical_or(\n",
    "                                       tf.greater_equal(tL_Kx1, (1 - 1e-3) * tp_Kx1),\n",
    "                                       tf.greater_equal(tR_Kx1, (1 - 1e-3) * tp_Kx1)\n",
    "                                   ),\n",
    "                                   tf.greater(\n",
    "                                       tf.sqrt(tL_Kx1) + tf.sqrt(tR_Kx1),\n",
    "                                       tf.sqrt(tp_Kx1)\n",
    "                                   )\n",
    "                                )\n",
    "                             )\n",
    "\n",
    "\n",
    "            def valid_calc(tp_Xx1, tL_Xx1, tR_Xx1, decay_factor_Xx1):\n",
    "\n",
    "                def get_logp(tP_local_Xx1, t_Xx1, t_cut, decay_factor_Xx1):\n",
    "                    \"\"\" Here we call the actual PDFs and CDFs defined in Eq (7) of the paper\"\"\"\n",
    "\n",
    "                    def prob_is_leaf(tP_local_Yx1, t_Yx1, t_cut, decay_factor_Yx1):\n",
    "                        \"\"\" The CDF defined in Eq (7) of the paper \"\"\"\n",
    "                        # Probability of the shower to stop F_s\n",
    "                        one_minus_cdf = 1 - tf.math.exp(- (1 - 1e-3)*decay_factor_Yx1)\n",
    "                        prob = - tf.math.log(one_minus_cdf)\\\n",
    "                               + tf.math.log(decay_factor_Yx1) - tf.math.log(tP_local_Yx1) - decay_factor_Yx1 * t_Yx1 / tP_local_Yx1\n",
    "                        return prob\n",
    "\n",
    "                    def prob_is_not_leaf(tP_local_Xx1, t_Xx1, t_cut, decay_factor_Xx1):\n",
    "                        \"\"\" The PDF defined in Eq (7) of the paper \"\"\"\n",
    "                        t_upper_Xx1 = tf.minimum(tP_local_Xx1, t_cut) #There are cases where tp2 < t_cut\n",
    "                        one_minus_cdf = 1 - tf.math.exp(- (1 - 1e-3) * decay_factor_Xx1)\n",
    "                        prob = -tf.math.log(one_minus_cdf) + \\\n",
    "                                tf.math.log(1 - tf.math.exp(- decay_factor_Xx1 * t_upper_Xx1 / tP_local_Xx1))\n",
    "                        return prob\n",
    "\n",
    "                    results_Xx1 = prob_is_not_leaf(tP_local_Xx1, t_Xx1, t_cut, decay_factor_Xx1)\n",
    "                    \n",
    "                    any_satisfy = tf.reduce_any(tf.greater(t_Xx1, t_cut))\n",
    "                    indices_Yx1 = tf.cond(any_satisfy,\n",
    "                     lambda: tf.where(tf.greater(t_Xx1, t_cut)),\n",
    "                     lambda: tf.constant([], dtype=tf.int64))\n",
    "                    #indices_Yx1 = tf.where(tf.greater(tf.squeeze(t_Xx1), t_cut))\n",
    "\n",
    "                    tP_local_new_Yx1 = tf.gather(tf.squeeze(tP_local_Xx1), indices_Yx1)\n",
    "                    t_new_Yx1 = tf.gather(tf.squeeze(t_Xx1), indices_Yx1)\n",
    "                    decay_factor_Yx1 = tf.gather(tf.squeeze(decay_factor_Xx1), indices_Yx1)\n",
    "\n",
    "                    updates_Yx1 = prob_is_leaf(tP_local_new_Yx1, t_new_Yx1, t_cut, decay_factor_Yx1)\n",
    "\n",
    "                    results_Xx1 = tf.tensor_scatter_nd_update(results_Xx1, indices_Yx1, updates_Yx1)\n",
    "\n",
    "                    return results_Xx1\n",
    "\n",
    "                # We always assign the left node as the node with the greater invariant mass for consistency\n",
    "                # To do this, we find the invariant mass squared for each node as a function of the parent\n",
    "                # by defining tpLR and tpRL using Eq (6) of the paper\n",
    "                # this is something akin to the parent invarinat mass in case left is bigger than right and the\n",
    "                # parent invariant mass in case right is bigger than left\n",
    "                tpLR_Xx1 = (tf.sqrt(tp_Xx1) - tf.sqrt(tL_Xx1)) ** 2\n",
    "                tpRL_Xx1 = (tf.sqrt(tp_Xx1) - tf.sqrt(tR_Xx1)) ** 2\n",
    "\n",
    "                # Calculate the log propobability using the CDFs and PDFs\n",
    "                # for each of the two cases where the left/right node is ultimately greater\n",
    "                logpLR_Xx1 = tf.cast(tf.math.log(1/2), dtype = tf.float64) + get_logp(tp_Xx1, tL_Xx1, t_cut,decay_factor_Xx1) + get_logp(tpLR_Xx1, tR_Xx1, t_cut, decay_factor_Xx1) \n",
    "\n",
    "                logpRL_Xx1 = tf.cast(tf.math.log(1/2), dtype = tf.float64) + get_logp(tp_Xx1, tR_Xx1, t_cut, decay_factor_Xx1) + get_logp(tpRL_Xx1, tL_Xx1, t_cut, decay_factor_Xx1)\n",
    "\n",
    "                # take the product of the two rightmost terms in Eq (8) where the one_minus_cdf term is distributed\n",
    "                logp_split_Xx1 = tf.reduce_logsumexp(tf.stack([logpLR_Xx1, logpRL_Xx1]), axis = 0)\n",
    "\n",
    "                # Add the term for the likelihood for sampling uniformly over a 2-sphere\n",
    "                logLH_Xx1 = logp_split_Xx1 + tf.math.log(1 / (4 * tf.constant(np.pi, dtype = tf.float64)))\n",
    "\n",
    "                return tf.cast(logLH_Xx1, dtype = tf.float64)\n",
    "\n",
    "\n",
    "            results_Kx1 = -tf.float64.max * tf.cast(tf.ones_like(is_negative_Kx1), dtype=tf.float64)\n",
    "\n",
    "            indices_Xx1 = tf.where(\n",
    "                            tf.logical_and(\n",
    "                                tf.logical_not(tf.squeeze(is_negative_Kx1)),\n",
    "                                tf.logical_not(tf.squeeze(is_invalid_Kx1))\n",
    "                            )\n",
    "                          )\n",
    "\n",
    "            tp_new_Xx1 = tf.gather(tf.squeeze(tp_Kx1), indices_Xx1)\n",
    "            tL_new_Xx1 = tf.gather(tf.squeeze(tL_Kx1), indices_Xx1)\n",
    "            tR_new_Xx1 = tf.gather(tf.squeeze(tR_Kx1), indices_Xx1)\n",
    "            decay_factor_Xx1 = tf.gather(tf.squeeze(decay_factor_Kx1), indices_Xx1)\n",
    "\n",
    "            updates_Xx1 = valid_calc(tp_new_Xx1, tL_new_Xx1, tR_new_Xx1, decay_factor_Xx1)\n",
    "\n",
    "            results_Kx1 = tf.tensor_scatter_nd_update(results_Kx1, indices_Xx1, updates_Xx1)\n",
    "            parent_vec4_Kx1x4 = tf.squeeze(l_data_Kx1x4 + r_data_Kx1x4)\n",
    "\n",
    "\n",
    "            results_Kx1_copied = tf.tile(\n",
    "                tf.reshape(\n",
    "                    tf.squeeze(results_Kx1), (-1, 1)\n",
    "                ), \n",
    "                (1, 4)\n",
    "            )\n",
    "\n",
    "            vec4_Kx4 = tf.squeeze(parent_vec4_Kx1x4)\n",
    "\n",
    "            like_stacked_vec4_Kx2x4 = tf.stack(\n",
    "                        [\n",
    "                            results_Kx1_copied,\n",
    "                            vec4_Kx4\n",
    "                        ],\n",
    "                        axis=1\n",
    "                    )\n",
    "            return like_stacked_vec4_Kx2x4, tL_Kx1, tR_Kx1, tp_Kx1"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
